<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Module ngx_http_upstream_module</title><style type="text/css">body { background: white; color: black; font-family: sans-serif; line-height: 1.4em; text-align: center; margin: 0; padding: 0; } #banner { background: black; color: #F2F2F2; line-height: 1.2em; padding: .3em 0; box-shadow: 0 5px 10px black; } #banner a { color: #00B140; } #main { text-align: left; margin: 0 auto; min-width: 32em; max-width: 64em; } #menu { float: right; width: 11em; padding: 0 .5em 1em .5em; border-left: 2px solid #DDD; } #content { margin-right: 13.5em; padding: 0 .2em 0 1.5em; } h1 { display: block; font-size: 3em; text-align: left; height: .7em; margin: 0; margin-bottom: .5em; } h1 img { width: 100%; } h2 { text-align: center; } p { text-align: justify; } table.news p { margin-top: 0; } table.news td { vertical-align: baseline; } table.news .date { text-align: right; padding-right: 0.5em; white-space: nowrap; } table.donors td { vertical-align: baseline; } table.donors li { text-align: left; } div.directive { background: #F2F2F2; line-height: 1em; margin: 1em 0 1em -1em; padding: .7em .7em .7em 1em; border-top: 2px solid #DDD; } div.directive th { padding-left: 0; padding-right: .5em; vertical-align: baseline; text-align: left; font-weight: normal; } div.directive td { vertical-align: baseline; } div.directive pre { padding: 0; margin: 0; } div.directive p { margin: .5em 0 0 .1em; font-size: .8em; } a.notrans { color: gray; text-decoration:none; } span.initial { font-size: 200%; float: left; padding-right: 10pt;} ul, ol { margin: .5em 0 1em 1em; padding: 0 .5em; } ol { list-style-position: inside; } li { text-align: justify; padding: .5em 0 0 1px; } .compact li { padding-top: 0; } dl { margin: .5em 0 1em 0; } dt { margin: .5em 0; } .compact dt { margin-bottom: .2em; } dd { margin-left: 1.5em; padding-left: 1px; text-align: justify; } td.list { background: #F2F2F2; } blockquote { margin: 1em 0 1em 1em; padding: .5em; } li blockquote, dd blockquote { margin: .7em 0; } blockquote.note { border: 1px dotted #999; line-height: 1.2em; text-align: justify; } blockquote.example { line-height: 1em; border-left: 1px solid #BBB; } blockquote.example pre { padding: 0; margin: 0; } sup { font-size: 50%; }</style><script>
        (function(w, d, s, l, i) {
            w[l] = w[l] || [];
            w[l].push({
                'gtm.start': new Date().getTime(),
                event: 'gtm.js'
            });
            var f = d.getElementsByTagName(s)[0],
                j = d.createElement(s),
                dl = l != 'dataLayer' ? '&l=' + l : '';
            j.async = true;
            j.src = '//www.googletagmanager.com/gtm.js?id=' + i + dl;
            f.parentNode.insertBefore(j, f);
        })(window, document, 'script', 'dataLayer', 'GTM-TPSP33');
    </script></head><body><div id="banner">
        Simplify your journey to microservices with the new NGINX Application Platform.<br><a href="https://www.nginx.com/blog/updating-nginx-application-platform/">Learn more</a></div><div id="main"><div id="menu"><h1><a href="/"><img src="/nginx.png" alt="nginx"></a></h1><div>english<br><a href="../../../ru/docs/http/ngx_http_upstream_module.html">русский</a><br><br><a href="../../../">news</a><br><a href="../../../en/">about</a><br><a href="../../../en/download.html">download</a><br><a href="../../../en/security_advisories.html">security</a><br><a href="../../../en/docs/">documentation</a><br><a href="../../../en/docs/faq.html">faq</a><br><a href="../../../en/books.html">books</a><br><a href="../../../en/support.html">support</a><br><br><a href="http://trac.nginx.org/nginx">trac</a><br><a href="http://twitter.com/nginxorg">twitter</a><br><a href="https://www.nginx.com/blog/">blog</a><br><br><a href="https://unit.nginx.org/">unit</a><br></div></div><div id="content"><h2>Module ngx_http_upstream_module</h2><table width="100%"><tr><td align="left"><a href="#example">Example Configuration</a><br><a href="#directives">Directives</a><br>     <a href="#upstream">upstream</a><br>     <a href="#server">server</a><br>     <a href="#zone">zone</a><br>     <a href="#state">state</a><br>     <a href="#hash">hash</a><br>     <a href="#ip_hash">ip_hash</a><br>     <a href="#keepalive">keepalive</a><br>     <a href="#ntlm">ntlm</a><br>     <a href="#least_conn">least_conn</a><br>     <a href="#least_time">least_time</a><br>     <a href="#queue">queue</a><br>     <a href="#sticky">sticky</a><br>     <a href="#sticky_cookie_insert">sticky_cookie_insert</a><br><a href="#variables">Embedded Variables</a><br></td></tr></table>

<a name="summary"></a><p>
The <code>ngx_http_upstream_module</code> module
is used to define groups of servers that can be referenced
by the <a href="ngx_http_proxy_module.html#proxy_pass">proxy_pass</a>,
<a href="ngx_http_fastcgi_module.html#fastcgi_pass">fastcgi_pass</a>,
<a href="ngx_http_uwsgi_module.html#uwsgi_pass">uwsgi_pass</a>,
<a href="ngx_http_scgi_module.html#scgi_pass">scgi_pass</a>,
<a href="ngx_http_memcached_module.html#memcached_pass">memcached_pass</a>, and
<a href="ngx_http_grpc_module.html#grpc_pass">grpc_pass</a> directives.
</p>


<a name="example"></a><center><h4>Example Configuration</h4></center><p>
</p> <blockquote class="example"><pre>
upstream <strong>backend</strong> {
    server backend1.example.com       weight=5;
    server backend2.example.com:8080;
    server unix:/tmp/backend3;

    server backup1.example.com:8080   backup;
    server backup2.example.com:8080   backup;
}

server {
    location / {
        proxy_pass http://<strong>backend</strong>;
    }
}
</pre></blockquote><p> 
</p><p>
Dynamically configurable group with
periodic <a href="ngx_http_upstream_hc_module.html">health checks</a> is
available as part of our
<a href="http://nginx.com/products/">commercial subscription</a>:
</p> <blockquote class="example"><pre>
resolver 10.0.0.1;

upstream <strong>dynamic</strong> {
    zone upstream_dynamic 64k;

    server backend1.example.com      weight=5;
    server backend2.example.com:8080 fail_timeout=5s slow_start=30s;
    server 192.0.2.1                 max_fails=3;
    server backend3.example.com      resolve;
    server backend4.example.com      service=http resolve;

    server backup1.example.com:8080  backup;
    server backup2.example.com:8080  backup;
}

server {
    location / {
        proxy_pass http://<strong>dynamic</strong>;
        health_check;
    }
}
</pre></blockquote><p> 
</p>


<a name="directives"></a><center><h4>Directives</h4></center><a name="upstream"></a><div class="directive"><table cellspacing="0">
                <tr>
                <th>
            Syntax:
                </th>
                <td>
            <code><strong>upstream</strong> <code><i>name</i></code> { ... }</code><br>
                </td>
                </tr>
            
                <tr>
                <th>
            Default:
                </th>
                <td>
            
            —
        
                </td>
                </tr>
            
                <tr>
                <th>
            Context:
                </th>
                <td>
            <code>http</code><br>
                </td>
                </tr>
            </table></div><p>
Defines a group of servers.
Servers can listen on different ports.
In addition, servers listening on TCP and UNIX-domain sockets
can be mixed.
</p><p>
Example:
</p> <blockquote class="example"><pre>
upstream backend {
    server backend1.example.com weight=5;
    server 127.0.0.1:8080       max_fails=3 fail_timeout=30s;
    server unix:/tmp/backend3;

    server backup1.example.com  backup;
}
</pre></blockquote><p> 
</p><p>
By default, requests are distributed between the servers using a
weighted round-robin balancing method.
In the above example, each 7 requests will be distributed as follows:
5 requests go to <code>backend1.example.com</code>
and one request to each of the second and third servers.
If an error occurs during communication with a server, the request will
be passed to the next server, and so on until all of the functioning
servers will be tried.
If a successful response could not be obtained from any of the servers,
the client will receive the result of the communication with the last server.
</p><a name="server"></a><div class="directive"><table cellspacing="0">
                <tr>
                <th>
            Syntax:
                </th>
                <td>
            <code><strong>server</strong> <code><i>address</i></code> [<code><i>parameters</i></code>];</code><br>
                </td>
                </tr>
            
                <tr>
                <th>
            Default:
                </th>
                <td>
            
            —
        
                </td>
                </tr>
            
                <tr>
                <th>
            Context:
                </th>
                <td>
            <code>upstream</code><br>
                </td>
                </tr>
            </table></div><p>
Defines the <code><i>address</i></code> and other <code><i>parameters</i></code>
of a server.
The address can be specified as a domain name or IP address,
with an optional port, or as a UNIX-domain socket path
specified after the “<code>unix:</code>” prefix.
If a port is not specified, the port 80 is used.
A domain name that resolves to several IP addresses defines
multiple servers at once.
</p><p>
The following parameters can be defined:
</p> <dl class="compact">

<dt id="weight">
<code>weight</code>=<code><i>number</i></code>
</dt>
<dd>
sets the weight of the server, by default, 1.
</dd>

<dt id="max_conns">
<code>max_conns</code>=<code><i>number</i></code>
</dt>
<dd>
limits the maximum <code><i>number</i></code> of simultaneous active
connections to the proxied server (1.11.5).
Default value is zero, meaning there is no limit.
If the server group does not reside in the <a href="#zone">shared memory</a>,
the limitation works per each worker process.
<blockquote class="note">
If <a href="#keepalive">idle keepalive</a> connections,
multiple <a href="../ngx_core_module.html#worker_processes">workers</a>,
and the <a href="#zone">shared memory</a> are enabled,
the total number of active and idle connections to the proxied server
may exceed the <code>max_conns</code> value.
</blockquote>
<blockquote class="note">
Since version 1.5.9 and prior to version 1.11.5,
this parameter was available as part of our
<a href="http://nginx.com/products/">commercial subscription</a>.
</blockquote>
</dd>

<dt id="max_fails">
<code>max_fails</code>=<code><i>number</i></code>
</dt>
<dd>
sets the number of unsuccessful attempts to communicate with the server
that should happen in the duration set by the <code>fail_timeout</code>
parameter to consider the server unavailable for a duration also set by the
<code>fail_timeout</code> parameter.
By default, the number of unsuccessful attempts is set to 1.
The zero value disables the accounting of attempts.
What is considered an unsuccessful attempt is defined by the
<a href="ngx_http_proxy_module.html#proxy_next_upstream">proxy_next_upstream</a>,
<a href="ngx_http_fastcgi_module.html#fastcgi_next_upstream">fastcgi_next_upstream</a>,
<a href="ngx_http_uwsgi_module.html#uwsgi_next_upstream">uwsgi_next_upstream</a>,
<a href="ngx_http_scgi_module.html#scgi_next_upstream">scgi_next_upstream</a>,
<a href="ngx_http_memcached_module.html#memcached_next_upstream">memcached_next_upstream</a>, and
<a href="ngx_http_grpc_module.html#grpc_next_upstream">grpc_next_upstream</a>
directives.
</dd>

<dt id="fail_timeout">
<code>fail_timeout</code>=<code><i>time</i></code>
</dt>
<dd>
sets
<ul class="compact">

<li>
the time during which the specified number of unsuccessful attempts to
communicate with the server should happen to consider the server unavailable;
</li>

<li>
and the period of time the server will be considered unavailable.
</li>

</ul>
By default, the parameter is set to 10 seconds.
</dd>

<dt id="backup">
<code>backup</code>
</dt>
<dd>
marks the server as a backup server.
It will be passed requests when the primary servers are unavailable.
</dd>

<dt id="down">
<code>down</code>
</dt>
<dd>
marks the server as permanently unavailable.
</dd>

</dl><p> 
</p><p>
Additionally,
the following parameters are available as part of our
<a href="http://nginx.com/products/">commercial subscription</a>:
</p> <dl class="compact">

<dt id="resolve">
<code>resolve</code>
</dt>
<dd>
monitors changes of the IP addresses
that correspond to a domain name of the server,
and automatically modifies the upstream configuration
without the need of restarting nginx (1.5.12).
The server group must reside in the <a href="#zone">shared memory</a>.
<p>
In order for this parameter to work,
the <a href="ngx_http_core_module.html#resolver">resolver</a> directive
must be specified in the
<a href="ngx_http_core_module.html#http">http</a> block.
Example:
</p> <blockquote class="example"><pre>
http {
    resolver 10.0.0.1;

    upstream u {
        zone ...;
        ...
        server example.com resolve;
    }
}
</pre></blockquote><p> 
</p>
</dd>

<dt id="route">
<code>route</code>=<code><i>string</i></code>
</dt>
<dd>
sets the server route name.
</dd>

<dt id="service">
<code>service</code>=<code><i>name</i></code>
</dt>
<dd>
enables resolving of DNS
<a href="https://tools.ietf.org/html/rfc2782">SRV</a>
records and sets the service <code><i>name</i></code> (1.9.13).
In order for this parameter to work, it is necessary to specify
the <a href="#resolve">resolve</a> parameter for the server
and specify a hostname without a port number.
<p>
If the service name does not contain a dot (“<code>.</code>”), then
the <a href="https://tools.ietf.org/html/rfc2782">RFC</a>-compliant name
is constructed
and the TCP protocol is added to the service prefix.
For example, to look up the
<code>_http._tcp.backend.example.com</code> SRV record,
it is necessary to specify the directive:
</p> <blockquote class="example"><pre>
server backend.example.com service=http resolve;
</pre></blockquote><p> 
If the service name contains one or more dots, then the name is constructed
by joining the service prefix and the server name.
For example, to look up the <code>_http._tcp.backend.example.com</code>
and <code>server1.backend.example.com</code> SRV records,
it is necessary to specify the directives:
</p> <blockquote class="example"><pre>
server backend.example.com service=_http._tcp resolve;
server example.com service=server1.backend resolve;
</pre></blockquote><p> 
</p>

<p>
Highest-priority SRV records
(records with the same lowest-number priority value)
are resolved as primary servers,
the rest of SRV records are resolved as backup servers.
If the <a href="#backup">backup</a> parameter is specified for the server,
high-priority SRV records are resolved as backup servers,
the rest of SRV records are ignored.
</p>
</dd>

<dt id="slow_start">
<code>slow_start</code>=<code><i>time</i></code>
</dt>
<dd>
sets the <code><i>time</i></code> during which the server will recover its weight
from zero to a nominal value, when unhealthy server becomes
<a href="ngx_http_upstream_hc_module.html#health_check">healthy</a>,
or when the server becomes available after a period of time
it was considered <a href="#fail_timeout">unavailable</a>.
Default value is zero, i.e. slow start is disabled.
<blockquote class="note">
The parameter cannot be used along with the
<a href="#hash">hash</a> and <a href="#ip_hash">ip_hash</a> load balancing methods.
</blockquote>
</dd>

<dt id="drain">
<code>drain</code>
</dt>
<dd>
puts the server into the “draining” mode (1.13.6).
In this mode, only requests <a href="#sticky">bound</a> to the server
will be proxied to it.
<blockquote class="note">
Prior to version 1.13.6,
the parameter could be changed only with the
<a href="ngx_http_api_module.html">API</a> module.
</blockquote>
</dd>

</dl><p> 
</p><p>
</p> <blockquote class="note">
If there is only a single server in a group, <code>max_fails</code>,
<code>fail_timeout</code> and <code>slow_start</code> parameters
are ignored, and such a server will never be considered unavailable.
</blockquote><p> 
</p><a name="zone"></a><div class="directive"><table cellspacing="0">
                <tr>
                <th>
            Syntax:
                </th>
                <td>
            <code><strong>zone</strong> <code><i>name</i></code> [<code><i>size</i></code>];</code><br>
                </td>
                </tr>
            
                <tr>
                <th>
            Default:
                </th>
                <td>
            
            —
        
                </td>
                </tr>
            
                <tr>
                <th>
            Context:
                </th>
                <td>
            <code>upstream</code><br>
                </td>
                </tr>
            </table><p>This directive appeared in version 1.9.0.
            </p></div><p>
Defines the <code><i>name</i></code> and <code><i>size</i></code> of the shared
memory zone that keeps the group’s configuration and run-time state that are
shared between worker processes.
Several groups may share the same zone.
In this case, it is enough to specify the <code><i>size</i></code> only once.
</p><p>
Additionally,
as part of our <a href="http://nginx.com/products/">commercial subscription</a>,
such groups allow changing the group membership
or modifying the settings of a particular server
without the need of restarting nginx.
The configuration is accessible via the
<a href="ngx_http_api_module.html">API</a> module (1.13.3).
</p> <blockquote class="note">
Prior to version 1.13.3,
the configuration was accessible only via a special location
handled by
<a href="ngx_http_upstream_conf_module.html#upstream_conf">upstream_conf</a>.
</blockquote><p> 
</p><a name="state"></a><div class="directive"><table cellspacing="0">
                <tr>
                <th>
            Syntax:
                </th>
                <td>
            <code><strong>state</strong> <code><i>file</i></code>;</code><br>
                </td>
                </tr>
            
                <tr>
                <th>
            Default:
                </th>
                <td>
            
            —
        
                </td>
                </tr>
            
                <tr>
                <th>
            Context:
                </th>
                <td>
            <code>upstream</code><br>
                </td>
                </tr>
            </table><p>This directive appeared in version 1.9.7.
            </p></div><p>
Specifies a <code><i>file</i></code> that keeps the state
of the dynamically configurable group.
</p><p>
Examples:
</p> <blockquote class="example"><pre>
state /var/lib/nginx/state/servers.conf; # path for Linux
state /var/db/nginx/state/servers.conf;  # path for FreeBSD
</pre></blockquote><p> 
</p><p>
The state is currently limited to the list of servers with their parameters.
The file is read when parsing the configuration and is updated each time
the upstream configuration is
<a href="ngx_http_upstream_conf_module.html#upstream_conf">changed</a>.
Changing the file content directly should be avoided.
The directive cannot be used
along with the <a href="#server">server</a> directive.
</p><p>
</p> <blockquote class="note">
Changes made during
<a href="../control.html#reconfiguration">configuration reload</a>
or <a href="../control.html#upgrade">binary upgrade</a>
can be lost.
</blockquote><p> 
</p><p>
</p> <blockquote class="note">
This directive is available as part of our
<a href="http://nginx.com/products/">commercial subscription</a>.
</blockquote><p> 
</p><a name="hash"></a><div class="directive"><table cellspacing="0">
                <tr>
                <th>
            Syntax:
                </th>
                <td>
            <code><strong>hash</strong> <code><i>key</i></code> [<code>consistent</code>];</code><br>
                </td>
                </tr>
            
                <tr>
                <th>
            Default:
                </th>
                <td>
            
            —
        
                </td>
                </tr>
            
                <tr>
                <th>
            Context:
                </th>
                <td>
            <code>upstream</code><br>
                </td>
                </tr>
            </table><p>This directive appeared in version 1.7.2.
            </p></div><p>
Specifies a load balancing method for a server group
where the client-server mapping is based on the hashed <code><i>key</i></code> value.
The <code><i>key</i></code> can contain text, variables, and their combinations.
Note that adding or removing a server from the group
may result in remapping most of the keys to different servers.
The method is compatible with the
<a href="http://search.cpan.org/perldoc?Cache%3A%3AMemcached">Cache::Memcached</a>
Perl library.
</p><p>
If the <code>consistent</code> parameter is specified
the <a href="http://www.last.fm/user/RJ/journal/2007/04/10/392555/">ketama</a>
consistent hashing method will be used instead.
The method ensures that only a few keys
will be remapped to different servers
when a server is added to or removed from the group.
This helps to achieve a higher cache hit ratio for caching servers.
The method is compatible with the
<a href="http://search.cpan.org/perldoc?Cache%3A%3AMemcached%3A%3AFast">Cache::Memcached::Fast</a>
Perl library with the <code><i>ketama_points</i></code> parameter set to 160.
</p><a name="ip_hash"></a><div class="directive"><table cellspacing="0">
                <tr>
                <th>
            Syntax:
                </th>
                <td>
            <code><strong>ip_hash</strong>;</code><br>
                </td>
                </tr>
            
                <tr>
                <th>
            Default:
                </th>
                <td>
            
            —
        
                </td>
                </tr>
            
                <tr>
                <th>
            Context:
                </th>
                <td>
            <code>upstream</code><br>
                </td>
                </tr>
            </table></div><p>
Specifies that a group should use a load balancing method where requests
are distributed between servers based on client IP addresses.
The first three octets of the client IPv4 address, or the entire IPv6 address,
are used as a hashing key.
The method ensures that requests from the same client will always be
passed to the same server except when this server is unavailable.
In the latter case client requests will be passed to another server.
Most probably, it will always be the same server as well.
</p> <blockquote class="note">
IPv6 addresses are supported starting from versions 1.3.2 and 1.2.2.
</blockquote><p> 
</p><p>
If one of the servers needs to be temporarily removed, it should
be marked with the <code>down</code> parameter in
order to preserve the current hashing of client IP addresses.
</p><p>
Example:
</p> <blockquote class="example"><pre>
upstream backend {
    ip_hash;

    server backend1.example.com;
    server backend2.example.com;
    server backend3.example.com <strong>down</strong>;
    server backend4.example.com;
}
</pre></blockquote><p> 
</p><p>
</p> <blockquote class="note">
Until versions 1.3.1 and 1.2.2, it was not possible to specify a weight for
servers using the <code>ip_hash</code> load balancing method.
</blockquote><p> 
</p><a name="keepalive"></a><div class="directive"><table cellspacing="0">
                <tr>
                <th>
            Syntax:
                </th>
                <td>
            <code><strong>keepalive</strong> <code><i>connections</i></code>;</code><br>
                </td>
                </tr>
            
                <tr>
                <th>
            Default:
                </th>
                <td>
            
            —
        
                </td>
                </tr>
            
                <tr>
                <th>
            Context:
                </th>
                <td>
            <code>upstream</code><br>
                </td>
                </tr>
            </table><p>This directive appeared in version 1.1.4.
            </p></div><p>
Activates the cache for connections to upstream servers.
</p><p>
The <code><i>connections</i></code> parameter sets the maximum number of
idle keepalive connections to upstream servers that are preserved in
the cache of each worker process.
When this number is exceeded, the least recently used connections
are closed.
</p> <blockquote class="note">
It should be particularly noted that the <code>keepalive</code> directive
does not limit the total number of connections to upstream servers
that an nginx worker process can open.
The <code><i>connections</i></code> parameter should be set to a number small enough
to let upstream servers process new incoming connections as well.
</blockquote><p> 
</p><p>
Example configuration of memcached upstream with keepalive connections:
</p> <blockquote class="example"><pre>
upstream memcached_backend {
    server 127.0.0.1:11211;
    server 10.0.0.2:11211;

    keepalive 32;
}

server {
    ...

    location /memcached/ {
        set $memcached_key $uri;
        memcached_pass memcached_backend;
    }

}
</pre></blockquote><p> 
</p><p>
For HTTP, the <a href="ngx_http_proxy_module.html#proxy_http_version">proxy_http_version</a>
directive should be set to “<code>1.1</code>”
and the “Connection” header field should be cleared:
</p> <blockquote class="example"><pre>
upstream http_backend {
    server 127.0.0.1:8080;

    keepalive 16;
}

server {
    ...

    location /http/ {
        proxy_pass http://http_backend;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
        ...
    }
}
</pre></blockquote><p> 
</p><p>
</p> <blockquote class="note">
Alternatively, HTTP/1.0 persistent connections can be used by passing the
“Connection: Keep-Alive” header field to an upstream server,
though this method is not recommended.
</blockquote><p> 
</p><p>
For FastCGI servers, it is required to set
<a href="ngx_http_fastcgi_module.html#fastcgi_keep_conn">fastcgi_keep_conn</a>
for keepalive connections to work:
</p> <blockquote class="example"><pre>
upstream fastcgi_backend {
    server 127.0.0.1:9000;

    keepalive 8;
}

server {
    ...

    location /fastcgi/ {
        fastcgi_pass fastcgi_backend;
        fastcgi_keep_conn on;
        ...
    }
}
</pre></blockquote><p> 
</p><p>
</p> <blockquote class="note">
When using load balancer methods other than the default
round-robin method, it is necessary to activate them before
the <code>keepalive</code> directive.
</blockquote><p> 

</p> <blockquote class="note">
SCGI and uwsgi protocols do not have a notion of keepalive connections.
</blockquote><p> 
</p><a name="ntlm"></a><div class="directive"><table cellspacing="0">
                <tr>
                <th>
            Syntax:
                </th>
                <td>
            <code><strong>ntlm</strong>;</code><br>
                </td>
                </tr>
            
                <tr>
                <th>
            Default:
                </th>
                <td>
            
            —
        
                </td>
                </tr>
            
                <tr>
                <th>
            Context:
                </th>
                <td>
            <code>upstream</code><br>
                </td>
                </tr>
            </table><p>This directive appeared in version 1.9.2.
            </p></div><p>
Allows proxying requests with
<a href="https://en.wikipedia.org/wiki/Integrated_Windows_Authentication">NTLM
Authentication</a>.
The upstream connection is bound to the client connection
once the client sends a request with the “Authorization”
header field value
starting with “<code>Negotiate</code>” or “<code>NTLM</code>”.
Further client requests will be proxied through the same upstream connection,
keeping the authentication context.
</p><p>
In order for NTLM authentication to work,
it is necessary to enable keepalive connections to upstream servers.
The <a href="ngx_http_proxy_module.html#proxy_http_version">proxy_http_version</a>
directive should be set to “<code>1.1</code>”
and the “Connection” header field should be cleared:
</p> <blockquote class="example"><pre>
upstream http_backend {
    server 127.0.0.1:8080;

    ntlm;
}

server {
    ...

    location /http/ {
        proxy_pass http://http_backend;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
        ...
    }
}
</pre></blockquote><p> 
</p><p>
</p> <blockquote class="note">
When using load balancer methods other than the default
round-robin method, it is necessary to activate them before
the <code>ntlm</code> directive.
</blockquote><p> 
</p><p>
</p> <blockquote class="note">
This directive is available as part of our
<a href="http://nginx.com/products/">commercial subscription</a>.
</blockquote><p> 
</p><a name="least_conn"></a><div class="directive"><table cellspacing="0">
                <tr>
                <th>
            Syntax:
                </th>
                <td>
            <code><strong>least_conn</strong>;</code><br>
                </td>
                </tr>
            
                <tr>
                <th>
            Default:
                </th>
                <td>
            
            —
        
                </td>
                </tr>
            
                <tr>
                <th>
            Context:
                </th>
                <td>
            <code>upstream</code><br>
                </td>
                </tr>
            </table>
                        <p>
                    This directive appeared in versions 1.3.1 and 1.2.2.
                    
                        </p>
                    </div><p>
Specifies that a group should use a load balancing method where a request
is passed to the server with the least number of active connections,
taking into account weights of servers.
If there are several such servers, they are tried in turn using a
weighted round-robin balancing method.
</p><a name="least_time"></a><div class="directive"><table cellspacing="0">
                <tr>
                <th>
            Syntax:
                </th>
                <td>
            <code><strong>least_time</strong> 
    <code>header</code> |
    <code>last_byte</code>
    [<code>inflight</code>];</code><br>
                </td>
                </tr>
            
                <tr>
                <th>
            Default:
                </th>
                <td>
            
            —
        
                </td>
                </tr>
            
                <tr>
                <th>
            Context:
                </th>
                <td>
            <code>upstream</code><br>
                </td>
                </tr>
            </table><p>This directive appeared in version 1.7.10.
            </p></div><p>
Specifies that a group should use a load balancing method where a request
is passed to the server with the least average response time and
least number of active connections, taking into account weights of servers.
If there are several such servers, they are tried in turn using a
weighted round-robin balancing method.
</p><p>
If the <code>header</code> parameter is specified,
time to receive the
<a href="#var_upstream_header_time">response header</a> is used.
If the <code>last_byte</code> parameter is specified,
time to receive the <a href="#var_upstream_response_time">full response</a>
is used.
If the <code>inflight</code> parameter is specified (1.11.6),
incomplete requests are also taken into account.
</p> <blockquote class="note">
Prior to version 1.11.6, incomplete requests were taken into account by default.
</blockquote><p> 
</p><p>
</p> <blockquote class="note">
This directive is available as part of our
<a href="http://nginx.com/products/">commercial subscription</a>.
</blockquote><p> 
</p><a name="queue"></a><div class="directive"><table cellspacing="0">
                <tr>
                <th>
            Syntax:
                </th>
                <td>
            <code><strong>queue</strong> 
<code><i>number</i></code>
[<code>timeout</code>=<code><i>time</i></code>];</code><br>
                </td>
                </tr>
            
                <tr>
                <th>
            Default:
                </th>
                <td>
            
            —
        
                </td>
                </tr>
            
                <tr>
                <th>
            Context:
                </th>
                <td>
            <code>upstream</code><br>
                </td>
                </tr>
            </table><p>This directive appeared in version 1.5.12.
            </p></div><p>
If an upstream server cannot be selected immediately
while processing a request,
the request will be placed into the queue.
The directive specifies the maximum <code><i>number</i></code> of requests
that can be in the queue at the same time.
If the queue is filled up,
or the server to pass the request to cannot be selected within
the time period specified in the <code>timeout</code> parameter,
the 502 (Bad Gateway)
error will be returned to the client.
</p><p>
The default value of the <code>timeout</code> parameter is 60 seconds.
</p><p>
</p> <blockquote class="note">
When using load balancer methods other than the default
round-robin method, it is necessary to activate them before
the <code>queue</code> directive.
</blockquote><p> 

</p> <blockquote class="note">
This directive is available as part of our
<a href="http://nginx.com/products/">commercial subscription</a>.
</blockquote><p> 
</p><a name="sticky"></a><div class="directive"><table cellspacing="0">
                <tr>
                <th>
            Syntax:
                </th>
                <td>
            <code><strong>sticky</strong> 
    <code>cookie</code> <code><i>name</i></code>
    [<code>expires=</code><code><i>time</i></code>]
    [<code>domain=</code><code><i>domain</i></code>]
    [<code>httponly</code>]
    [<code>secure</code>]
    [<code>path=</code><code><i>path</i></code>];</code><br><code><strong>sticky</strong> 
    <code>route</code> <code><i>$variable</i></code> ...;</code><br><code><strong>sticky</strong> 
    <code>learn</code>
    <code>create=</code><code><i>$variable</i></code>
    <code>lookup=</code><code><i>$variable</i></code>
    <code>zone=</code><code><i>name</i></code>:<code><i>size</i></code>
    [<code>timeout=</code><code><i>time</i></code>]
    [<code>header</code>]
    [<code>sync</code>];</code><br>
                </td>
                </tr>
            
                <tr>
                <th>
            Default:
                </th>
                <td>
            
            —
        
                </td>
                </tr>
            
                <tr>
                <th>
            Context:
                </th>
                <td>
            <code>upstream</code><br>
                </td>
                </tr>
            </table><p>This directive appeared in version 1.5.7.
            </p></div><p>
Enables session affinity, which causes requests from the same client to be
passed to the same server in a group of servers.
Three methods are available:
</p> <dl class="compact">
<dt id="sticky_cookie"><code>cookie</code></dt>
<dd>

<p>
When the <code>cookie</code> method is used, information about the
designated server is passed in an HTTP cookie generated by nginx:
</p> <blockquote class="example"><pre>
upstream backend {
    server backend1.example.com;
    server backend2.example.com;

    sticky cookie srv_id expires=1h domain=.example.com path=/;
}
</pre></blockquote><p> 
</p>

<p>
A request that comes from a client not yet bound to a particular server
is passed to the server selected by the configured balancing method.
Further requests with this cookie will be passed to the designated server.
If the designated server cannot process a request, the new server is
selected as if the client has not been bound yet.
</p>

<p>
The first parameter sets the name of the cookie to be set or inspected.
The cookie value is
a hexadecimal representation of the MD5 hash of the IP address and port,
or of the UNIX-domain socket path.
However, if the “<code>route</code>” parameter of the
<a href="#server">server</a> directive is specified, the cookie value will be
the value of the “<code>route</code>” parameter:
</p> <blockquote class="example"><pre>
upstream backend {
    server backend1.example.com route=<strong>a</strong>;
    server backend2.example.com route=<strong>b</strong>;

    sticky cookie srv_id expires=1h domain=.example.com path=/;
}
</pre></blockquote><p> 
In this case, the value of the “<code>srv_id</code>” cookie will be
either <code><i>a</i></code> or <code><i>b</i></code>.
</p>

<p>
Additional parameters may be as follows:
</p> <dl class="compact">

<dt><code>expires=</code><code><i>time</i></code></dt>
<dd>
Sets the <code><i>time</i></code> for which a browser should keep the cookie.
The special value <code>max</code> will cause the cookie to expire on
“<code>31 Dec 2037 23:55:55 GMT</code>”.
If the parameter is not specified, it will cause the cookie to expire at
the end of a browser session.
</dd>

<dt><code>domain=</code><code><i>domain</i></code></dt>
<dd>
Defines the <code><i>domain</i></code> for which the cookie is set.
Parameter value can contain variables (1.11.5).
</dd>

<dt><code>httponly</code></dt>
<dd>
Adds the <code>HttpOnly</code> attribute to the cookie (1.7.11).
</dd>

<dt><code>secure</code></dt>
<dd>
Adds the <code>Secure</code> attribute to the cookie (1.7.11).

</dd>

<dt><code>path=</code><code><i>path</i></code></dt>
<dd>
Defines the <code><i>path</i></code> for which the cookie is set.
</dd>

</dl><p> 
If any parameters are omitted, the corresponding cookie fields are not set.
</p>
</dd>

<dt id="sticky_route"><code>route</code></dt>
<dd>

<p>
When the <code>route</code> method is used, proxied server assigns
client a route on receipt of the first request.
All subsequent requests from this client will carry routing information
in a cookie or URI.
This information is compared with the “<code>route</code>” parameter
of the <a href="#server">server</a> directive to identify the server to which the
request should be proxied.
If the “<code>route</code>” parameter is not specified, the route name
will be a hexadecimal representation of the MD5 hash of the IP address and port,
or of the UNIX-domain socket path.
If the designated server cannot process a request, the new server is
selected by the configured balancing method as if there is no routing
information in the request.
</p>

<p>
The parameters of the <code>route</code> method specify variables that
may contain routing information.
The first non-empty variable is used to find the matching server.
</p>

<p>
Example:
</p> <blockquote class="example"><pre>
map $cookie_jsessionid $route_cookie {
    ~.+\.(?P&lt;route&gt;\w+)$ $route;
}

map $request_uri $route_uri {
    ~jsessionid=.+\.(?P&lt;route&gt;\w+)$ $route;
}

upstream backend {
    server backend1.example.com route=a;
    server backend2.example.com route=b;

    sticky route $route_cookie $route_uri;
}
</pre></blockquote><p> 
Here, the route is taken from the “<code>JSESSIONID</code>” cookie
if present in a request.
Otherwise, the route from the URI is used.
</p>

</dd>

<dt id="sticky_learn"><code>learn</code></dt>
<dd>
<p>
When the <code>learn</code> method (1.7.1) is used, nginx
analyzes upstream server responses and learns server-initiated sessions
usually passed in an HTTP cookie.
</p> <blockquote class="example"><pre>
upstream backend {
   server backend1.example.com:8080;
   server backend2.example.com:8081;

   sticky learn
          create=$upstream_cookie_examplecookie
          lookup=$cookie_examplecookie
          zone=client_sessions:1m;
}
</pre></blockquote><p> 

In the example, the upstream server creates a session by setting the
cookie “<code>EXAMPLECOOKIE</code>” in the response.
Further requests with this cookie will be passed to the same server.
If the server cannot process the request, the new server is
selected as if the client has not been bound yet.
</p>

<p>
The parameters <code>create</code> and <code>lookup</code>
specify variables that indicate how new sessions are created and existing
sessions are searched, respectively.
Both parameters may be specified more than once, in which case the first
non-empty variable is used.
</p>

<p>
Sessions are stored in a shared memory zone, whose <code><i>name</i></code> and
<code><i>size</i></code> are configured by the <code>zone</code> parameter.
One megabyte zone can store about 4000 sessions on the 64-bit platform.
The sessions that are not accessed during the time specified by the
<code>timeout</code> parameter get removed from the zone.
By default, <code>timeout</code> is set to 10 minutes.
</p>

<a name="sticky_learn_header"></a><p>
The <code>header</code> parameter (1.13.1) allows creating a session
right after receiving response headers from the upstream server.
</p>

<a name="sticky_learn_sync"></a><p>
The <code>sync</code> parameter (1.13.8) enables
<a href="../stream/ngx_stream_zone_sync_module.html#zone_sync">synchronization</a>
of the shared memory zone.
</p>

</dd>
</dl><p> 
</p><p>
</p> <blockquote class="note">
This directive is available as part of our
<a href="http://nginx.com/products/">commercial subscription</a>.
</blockquote><p> 
</p><a name="sticky_cookie_insert"></a><div class="directive"><table cellspacing="0">
                <tr>
                <th>
            Syntax:
                </th>
                <td>
            <code><strong>sticky_cookie_insert</strong> <code><i>name</i></code>
[<code>expires=</code><code><i>time</i></code>]
[<code>domain=</code><code><i>domain</i></code>]
[<code>path=</code><code><i>path</i></code>];</code><br>
                </td>
                </tr>
            
                <tr>
                <th>
            Default:
                </th>
                <td>
            
            —
        
                </td>
                </tr>
            
                <tr>
                <th>
            Context:
                </th>
                <td>
            <code>upstream</code><br>
                </td>
                </tr>
            </table></div><p>
This directive is obsolete since version 1.5.7.
An equivalent
<a href="#sticky">sticky</a> directive with a new syntax should be used instead:
</p> <blockquote class="note">
<code>sticky cookie</code> <code><i>name</i></code>
[<code>expires=</code><code><i>time</i></code>]
[<code>domain=</code><code><i>domain</i></code>]
[<code>path=</code><code><i>path</i></code>];
</blockquote><p> 
</p>


<a name="variables"></a><center><h4>Embedded Variables</h4></center><p>
The <code>ngx_http_upstream_module</code> module
supports the following embedded variables:
</p> <dl class="compact">

<dt id="var_upstream_addr"><code>$upstream_addr</code></dt>
<dd>
keeps the IP address and port,
or the path to the UNIX-domain socket of the upstream server.
If several servers were contacted during request processing,
their addresses are separated by commas, e.g.
“<code>192.168.1.1:80, 192.168.1.2:80, unix:/tmp/sock</code>”.
If an internal redirect from one server group to another happens,
initiated by
“X-Accel-Redirect” or
<a href="ngx_http_core_module.html#error_page">error_page</a>,
then the server addresses from different groups are separated by colons, e.g.
“<code>192.168.1.1:80, 192.168.1.2:80, unix:/tmp/sock : 192.168.10.1:80, 192.168.10.2:80</code>”.
If a server cannot be selected,
the variable keeps the name of the server group.
</dd>

<dt id="var_upstream_bytes_received"><code>$upstream_bytes_received</code></dt>
<dd>
number of bytes received from an upstream server (1.11.4).
Values from several connections
are separated by commas and colons like addresses in the
<a href="#var_upstream_addr">$upstream_addr</a> variable.
</dd>

<dt id="var_upstream_cache_status"><code>$upstream_cache_status</code>
</dt>
<dd>
keeps the status of accessing a response cache (0.8.3).
The status can be either “<code>MISS</code>”,
“<code>BYPASS</code>”, “<code>EXPIRED</code>”,
“<code>STALE</code>”, “<code>UPDATING</code>”,
“<code>REVALIDATED</code>”, or “<code>HIT</code>”.
</dd>

<dt id="var_upstream_connect_time"><code>$upstream_connect_time</code>
</dt>
<dd>
keeps time spent on establishing a connection with the upstream server (1.9.1);
the time is kept in seconds with millisecond resolution.
In case of SSL, includes time spent on handshake.
Times of several connections
are separated by commas and colons like addresses in the
<a href="#var_upstream_addr">$upstream_addr</a> variable.
</dd>

<dt id="var_upstream_cookie_"><code>$upstream_cookie_</code><code><i>name</i></code>
</dt>
<dd>
cookie with the specified <code><i>name</i></code> sent by the upstream server
in the “Set-Cookie” response header field (1.7.1).
Only the cookies from the response of the last server are saved.
</dd>

<dt id="var_upstream_header_time"><code>$upstream_header_time</code>
</dt>
<dd>
keeps time
spent on receiving the response header from the upstream server (1.7.10);
the time is kept in seconds with millisecond resolution.
Times of several responses
are separated by commas and colons like addresses in the
<a href="#var_upstream_addr">$upstream_addr</a> variable.
</dd>

<dt id="var_upstream_http_"><code>$upstream_http_</code><code><i>name</i></code></dt>
<dd>
keep server response header fields.
For example, the “Server” response header field
is available through the <code>$upstream_http_server</code> variable.
The rules of converting header field names to variable names are the same
as for the variables that start with the
“<a href="ngx_http_core_module.html#var_http_">$http_</a>” prefix.
Only the header fields from the response of the last server are saved.
</dd>

<dt id="var_upstream_queue_time"><code>$upstream_queue_time</code></dt>
<dd>
keeps time the request spent in the upstream <a href="#queue">queue</a>
(1.13.9);
the time is kept in seconds with millisecond resolution.
Times of several responses
are separated by commas and colons like addresses in the
<a href="#var_upstream_addr">$upstream_addr</a> variable.
</dd>

<dt id="var_upstream_response_length"><code>$upstream_response_length</code>
</dt>
<dd>
keeps the length of the response obtained from the upstream server (0.7.27);
the length is kept in bytes.
Lengths of several responses
are separated by commas and colons like addresses in the
<a href="#var_upstream_addr">$upstream_addr</a> variable.
</dd>

<dt id="var_upstream_response_time"><code>$upstream_response_time</code>
</dt>
<dd>
keeps time spent on receiving the response from the upstream server;
the time is kept in seconds with millisecond resolution.
Times of several responses
are separated by commas and colons like addresses in the
<a href="#var_upstream_addr">$upstream_addr</a> variable.
</dd>

<dt id="var_upstream_status"><code>$upstream_status</code></dt>
<dd>
keeps status code of the response obtained from the upstream server.
Status codes of several responses
are separated by commas and colons like addresses in the
<a href="#var_upstream_addr">$upstream_addr</a> variable.
If a server cannot be selected,
the variable keeps the 502 (Bad Gateway) status code.
</dd>

<dt id="var_upstream_trailer_"><code>$upstream_trailer_</code><code><i>name</i></code></dt>
<dd>
keeps fields from the end of the response
obtained from the upstream server (1.13.10).
</dd>

</dl><p> 
</p>

</div></div></body></html>
